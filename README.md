# FakeNewsBuster

This repo is the product of working with Jackie Girgis and Maneeshika Madduri to build fake news classification pipelines based on the Liar dataset.


# Abstract
Fake news detection has become a crucial area of research due to its impact on public opinion and trust. Dissemination of fake news can undermine trust in institutions, and detecting sources of fake news rapidly is important to limiting the spread of misinformation. In our work, we demonstrate how NLP processing and models can be used to identify and classify fake news encountered in the media. This project utilizes the LIAR dataset (Wang, 2017), which contains 12.8K news statements (split into 11,524 samples for the training set, and 1,267 for the testing set) collected over a decade from PolitiFact. The news statements in the LIAR dataset have been categorized into six classes (true, mostly true, half-true, mostly false, false, pants on fire), to develop a model capable of accurately classifying political news items. Text preprocessing involved tokenization, lowercasing, removal of punctuation and custom stop words, and embedding to convert tokens into numerical representations. We implemented a Bidirectional Long Short-Term Memory (BiLSTM) network with two dense layers and a final classification layer using a sigmoid activation function. The model was trained with a learning rate of 0.001 using batches of 50 samples over 10 epochs. We compared this model against simpler models, including Logistic Regression and LSTM. All three models had similar accuracies of 23% (chance is 17% for this dataset) for the 6-class classification problem. These accuracies are similar to results from prior work with this dataset. Reasons for this modest accuracy might be because of the subjectivity of the labels and the heterogeneity of the dataset. Given these modest accuracies, our next steps are to tune and test our data with Transformer models and to leverage the data power that these pre-trained models hold. 
